{"id":1790,"name":"estimateTokenLength","kind":64,"kindString":"Function","flags":{},"children":[],"sources":[{"fileName":"packages/ai-utils/src/llm/prompts/token.ts","fullFileName":"/home/runner/work/fe-tools/fe-tools/utils/packages/ai-utils/src/llm/prompts/token.ts","line":45,"character":16,"url":"https://github.com/MichealWayne/fe-tools/blob/e75b369/utils/packages/ai-utils/src/llm/prompts/token.ts#L45"}],"signatures":[{"id":1791,"name":"estimateTokenLength","kind":4096,"kindString":"Call signature","flags":{},"comment":{"summary":[],"blockTags":[{"tag":"@function","content":[{"kind":"text","text":"estimateTokenLength"}]},{"tag":"@description","content":[{"kind":"text","text":"估算字符串中的token数量。A simple heuristic to estimate the number of tokens in a string using character-based approximation for various language models."}]},{"tag":"@returns","content":[{"kind":"text","text":"估算的token数量。The estimated number of tokens (rough approximation)"}]},{"tag":"@example","content":[{"kind":"code","text":"```ts\n// Estimate tokens for English text\nconst englishTokens = estimateTokenLength('Hello, how are you today?');\nconsole.log(englishTokens); // Approximately 6-8 tokens\n```"}]},{"tag":"@example","content":[{"kind":"code","text":"```ts\n// Estimate tokens for Chinese text\nconst chineseTokens = estimateTokenLength('你好，今天怎么样？');\nconsole.log(chineseTokens); // Approximately 8-10 tokens\n```"}]},{"tag":"@example","content":[{"kind":"code","text":"```ts\n// Estimate tokens for code\nconst codeTokens = estimateTokenLength('function hello() { return \"world\"; }');\nconsole.log(codeTokens); // Approximately 8-12 tokens\n```"}]},{"tag":"@example","content":[{"kind":"code","text":"```ts\n// Check if prompt fits within model limits\nconst prompt = 'Generate a summary of this article...';\nconst tokens = estimateTokenLength(prompt);\nconst maxTokens = 4096;\nif (tokens > maxTokens * 0.8) {\n  console.warn('Prompt may be too long for model');\n}\n```"}]},{"tag":"@see","content":[{"kind":"inline-tag","tag":"@link","text":"https://www.npmjs.com/package/tiktoken","target":"https://www.npmjs.com/package/tiktoken"},{"kind":"text","text":" - For precise OpenAI token counting"}]}]},"parameters":[{"id":1792,"name":"input","kind":32768,"kindString":"Parameter","flags":{},"comment":{"summary":[{"kind":"text","text":"需要估算token数量的字符串。The string to estimate token length for (supports multilingual text)"}]},"type":{"type":"intrinsic","name":"string"},"text":{"comment":"<p>需要估算token数量的字符串。The string to estimate token length for (supports multilingual text)</p>\n"}}],"type":{"type":"intrinsic","name":"number"},"is":{"declaration":false},"location":{"query":"AIUtils.Function.estimateTokenLength","hash":"estimateTokenLength"},"text":{"comment":"<h5>Function:</h5><p>estimateTokenLength</p>\n<h5>Description:</h5><p>估算字符串中的token数量。A simple heuristic to estimate the number of tokens in a string using character-based approximation for various language models.</p>\n<h5>Returns:</h5><p>估算的token数量。The estimated number of tokens (rough approximation)</p>\n<h5>Example:</h5><pre><code class=\"language-ts\"><span class=\"pl-c\">// Estimate tokens for English text</span>\n<span class=\"pl-k\">const</span> <span class=\"pl-c1\">englishTokens</span> <span class=\"pl-k\">=</span> <span class=\"pl-en\">estimateTokenLength</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Hello, how are you today?<span class=\"pl-pds\">'</span></span>);\n<span class=\"pl-c1\">console</span>.<span class=\"pl-c1\">log</span>(<span class=\"pl-smi\">englishTokens</span>); <span class=\"pl-c\">// Approximately 6-8 tokens</span>\n</code></pre>\n<h5>Example:</h5><pre><code class=\"language-ts\"><span class=\"pl-c\">// Estimate tokens for Chinese text</span>\n<span class=\"pl-k\">const</span> <span class=\"pl-c1\">chineseTokens</span> <span class=\"pl-k\">=</span> <span class=\"pl-en\">estimateTokenLength</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>你好，今天怎么样？<span class=\"pl-pds\">'</span></span>);\n<span class=\"pl-c1\">console</span>.<span class=\"pl-c1\">log</span>(<span class=\"pl-smi\">chineseTokens</span>); <span class=\"pl-c\">// Approximately 8-10 tokens</span>\n</code></pre>\n<h5>Example:</h5><pre><code class=\"language-ts\"><span class=\"pl-c\">// Estimate tokens for code</span>\n<span class=\"pl-k\">const</span> <span class=\"pl-c1\">codeTokens</span> <span class=\"pl-k\">=</span> <span class=\"pl-en\">estimateTokenLength</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>function hello() { return \"world\"; }<span class=\"pl-pds\">'</span></span>);\n<span class=\"pl-c1\">console</span>.<span class=\"pl-c1\">log</span>(<span class=\"pl-smi\">codeTokens</span>); <span class=\"pl-c\">// Approximately 8-12 tokens</span>\n</code></pre>\n<h5>Example:</h5><pre><code class=\"language-ts\"><span class=\"pl-c\">// Check if prompt fits within model limits</span>\n<span class=\"pl-k\">const</span> <span class=\"pl-c1\">prompt</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Generate a summary of this article...<span class=\"pl-pds\">'</span></span>;\n<span class=\"pl-k\">const</span> <span class=\"pl-c1\">tokens</span> <span class=\"pl-k\">=</span> <span class=\"pl-en\">estimateTokenLength</span>(<span class=\"pl-smi\">prompt</span>);\n<span class=\"pl-k\">const</span> <span class=\"pl-c1\">maxTokens</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4096</span>;\n<span class=\"pl-k\">if</span> (<span class=\"pl-smi\">tokens</span> <span class=\"pl-k\">></span> <span class=\"pl-smi\">maxTokens</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">0.8</span>) {\n  <span class=\"pl-c1\">console</span>.<span class=\"pl-c1\">warn</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Prompt may be too long for model<span class=\"pl-pds\">'</span></span>);\n}\n</code></pre>\n<h5>See:</h5><p><a href=\"https://www.npmjs.com/package/tiktoken\">https://www.npmjs.com/package/tiktoken</a> - For precise OpenAI token counting</p>\n"},"sources":[{"fileName":"packages/ai-utils/src/llm/prompts/token.ts","fullFileName":"/home/runner/work/fe-tools/fe-tools/utils/packages/ai-utils/src/llm/prompts/token.ts","line":45,"character":0,"url":"https://github.com/MichealWayne/fe-tools/blob/e75b369/utils/packages/ai-utils/src/llm/prompts/token.ts#L45"}],"parentId":1790}],"is":{"declaration":true},"location":{"query":"AIUtils.Function.estimateTokenLength","hash":""},"text":{},"parentId":1169}
