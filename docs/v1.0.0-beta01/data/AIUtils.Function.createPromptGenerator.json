{"id":1797,"name":"createPromptGenerator","kind":64,"kindString":"Function","flags":{},"children":[],"sources":[{"fileName":"packages/ai-utils/src/utils/prompt/generator.ts","fullFileName":"/home/runner/work/fe-tools/fe-tools/utils/packages/ai-utils/src/utils/prompt/generator.ts","line":42,"character":16,"url":"https://github.com/MichealWayne/fe-tools/blob/e75b369/utils/packages/ai-utils/src/utils/prompt/generator.ts#L42"}],"signatures":[{"id":1798,"name":"createPromptGenerator","kind":4096,"kindString":"Call signature","flags":{},"comment":{"summary":[{"kind":"text","text":"Creates a reusable prompt generator function.\n\nThis higher-order function encapsulates common logic like token length checking,\nallowing specific prompt content generation to be handled by the provided "},{"kind":"code","text":"`contentGenerator`"},{"kind":"text","text":"."}],"blockTags":[{"tag":"@returns","content":[{"kind":"text","text":"A function that generates the full prompt string based on the input, or an empty string if it exceeds the token limit."}]},{"tag":"@example","content":[{"kind":"text","text":"const myPromptGenerator = createPromptGenerator(\n  { maxTokenLength: 10000 },\n  (userQuery: string) => "},{"kind":"code","text":"`Answer the following question: ${userQuery}`"},{"kind":"text","text":"\n);\nconst prompt = myPromptGenerator(\"What is the weather today?\");\nif (prompt) {\n  // Use the prompt with an LLM API\n} else {\n  console.error(\"Prompt was too long\");\n}"}]}]},"typeParameter":[{"id":1799,"name":"T","kind":131072,"kindString":"Type parameter","flags":{},"comment":{"summary":[{"kind":"text","text":"The type of the input parameter for the content generator function."}]}}],"parameters":[{"id":1800,"name":"config","kind":32768,"kindString":"Parameter","flags":{},"comment":{"summary":[{"kind":"text","text":"Configuration for the prompt generator, including maximum token length."}]},"type":{"type":"reference","id":1795,"name":"PromptConfig"},"text":{"comment":"<p>Configuration for the prompt generator, including maximum token length.</p>\n"}},{"id":1801,"name":"contentGenerator","kind":32768,"kindString":"Parameter","flags":{},"comment":{"summary":[{"kind":"text","text":"A function that takes the input and returns the core prompt content."}]},"type":{"type":"reflection","declaration":{"id":1802,"name":"__type","kind":65536,"kindString":"Type literal","flags":{},"sources":[{"fileName":"packages/ai-utils/src/utils/prompt/generator.ts","line":44,"character":20,"url":"https://github.com/MichealWayne/fe-tools/blob/e75b369/utils/packages/ai-utils/src/utils/prompt/generator.ts#L44"}],"signatures":[{"id":1803,"name":"__type","kind":4096,"kindString":"Call signature","flags":{},"parameters":[{"id":1804,"name":"input","kind":32768,"kindString":"Parameter","flags":{},"type":{"type":"reference","id":1799,"name":"T"}}],"type":{"type":"intrinsic","name":"string"}}]}},"text":{"comment":"<p>A function that takes the input and returns the core prompt content.</p>\n"}}],"type":{"type":"reflection","declaration":{"id":1805,"name":"createPromptGenerator","kind":65536,"kindString":"Type literal","flags":{},"sources":[{"fileName":"packages/ai-utils/src/utils/prompt/generator.ts","line":45,"character":3,"url":"https://github.com/MichealWayne/fe-tools/blob/e75b369/utils/packages/ai-utils/src/utils/prompt/generator.ts#L45"}],"signatures":[{"id":1806,"name":"createPromptGenerator","kind":4096,"kindString":"Call signature","flags":{},"parameters":[{"id":1807,"name":"input","kind":32768,"kindString":"Parameter","flags":{},"type":{"type":"reference","id":1799,"name":"T"},"text":{}}],"type":{"type":"intrinsic","name":"string"},"is":{"declaration":false},"location":{"query":"AIUtils.Function.createPromptGenerator","hash":"createPromptGenerator.__type"},"text":{},"parentId":1797}],"location":{"query":"AIUtils.Function.createPromptGenerator","hash":"createPromptGenerator"}}},"is":{"declaration":false},"location":{"query":"AIUtils.Function.createPromptGenerator","hash":"createPromptGenerator"},"text":{"comment":"<p>Creates a reusable prompt generator function.</p>\n<p>This higher-order function encapsulates common logic like token length checking,\nallowing specific prompt content generation to be handled by the provided <code>contentGenerator</code>.</p>\n<h5>Returns:</h5><p>A function that generates the full prompt string based on the input, or an empty string if it exceeds the token limit.</p>\n<h5>Example:</h5><p>const myPromptGenerator = createPromptGenerator(\n  { maxTokenLength: 10000 },\n  (userQuery: string) =&gt; <code>Answer the following question: ${userQuery}</code>\n);\nconst prompt = myPromptGenerator(&quot;What is the weather today?&quot;);\nif (prompt) {\n  // Use the prompt with an LLM API\n} else {\n  console.error(&quot;Prompt was too long&quot;);\n}</p>\n"},"sources":[{"fileName":"packages/ai-utils/src/utils/prompt/generator.ts","fullFileName":"/home/runner/work/fe-tools/fe-tools/utils/packages/ai-utils/src/utils/prompt/generator.ts","line":42,"character":0,"url":"https://github.com/MichealWayne/fe-tools/blob/e75b369/utils/packages/ai-utils/src/utils/prompt/generator.ts#L42"}],"parentId":1797}],"is":{"declaration":true},"location":{"query":"AIUtils.Function.createPromptGenerator","hash":""},"text":{},"parentId":1169}
